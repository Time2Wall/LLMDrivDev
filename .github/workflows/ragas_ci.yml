# GitHub Actions CI/CD Pipeline for Ragas LLM Testing
# File: .github/workflows/ragas_ci.yml

name: Ragas LLM Quality Tests

on:
  push:
    branches: [main, develop]
    paths:
      - 'hometask_9/**'
  pull_request:
    branches: [main]
    paths:
      - 'hometask_9/**'
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.12'
  OLLAMA_MODEL: 'qwen2.5:1.5b'

jobs:
  ragas-tests:
    name: Run Ragas Evaluation Tests
    runs-on: ubuntu-latest
    timeout-minutes: 45

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install Ollama
        run: |
          echo "::group::Installing Ollama"
          curl -fsSL https://ollama.com/install.sh | sh
          echo "::endgroup::"

      - name: Start Ollama and pull model
        run: |
          echo "::group::Starting Ollama server"
          ollama serve &
          # Wait for Ollama to be ready
          for i in $(seq 1 30); do
            if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
              echo "Ollama is ready after ${i}s"
              break
            fi
            echo "Waiting for Ollama... (${i}/30)"
            sleep 1
          done
          echo "::endgroup::"

          echo "::group::Pulling model ${{ env.OLLAMA_MODEL }}"
          ollama pull ${{ env.OLLAMA_MODEL }}
          echo "::endgroup::"

          echo "::group::Verifying model"
          ollama list
          echo "::endgroup::"

      - name: Install dependencies
        run: |
          cd hometask_9
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Sanitize notebook (strip IDE-specific fields)
        run: |
          cd hometask_9
          python -c "
          import json
          with open('hometask_9.ipynb', 'r') as f:
              nb = json.load(f)
          for cell in nb['cells']:
              if cell['cell_type'] == 'code':
                  for output in cell.get('outputs', []):
                      output.pop('jetTransient', None)
                  cell['outputs'] = []
              else:
                  cell.pop('outputs', None)
                  cell.pop('execution_count', None)
          with open('hometask_9.ipynb', 'w') as f:
              json.dump(nb, f, indent=1)
          print('Notebook sanitized: cleared outputs and IDE-specific fields')
          "

      - name: Verify test data exists
        run: |
          cd hometask_9
          ls -la tests/goldens.json

      - name: Run Ragas evaluation notebook
        env:
          CI: "true"
        run: |
          cd hometask_9
          echo "Starting notebook execution at $(date)"
          jupyter nbconvert --to notebook --execute hometask_9.ipynb \
            --ExecutePreprocessor.timeout=900 \
            --output hometask_9_executed.ipynb \
            --log-level=INFO
          echo "Notebook execution finished at $(date)"
        continue-on-error: false

      - name: Run pytest quality gates
        run: |
          cd hometask_9
          pytest tests/test_ragas_evaluation.py -v --tb=long --junitxml=test-results.xml

      # Quality Gate: Pipeline fails if metrics are below thresholds
      - name: Check quality gates
        run: |
          cd hometask_9
          python -c "
          import json, sys
          with open('ragas_results.json') as f:
              results = json.load(f)
          metrics = results['aggregate_metrics']
          thresholds = results['thresholds']
          failed = False
          for metric, threshold in thresholds.items():
              value = metrics.get(metric, 0)
              status = 'PASS' if value >= threshold else 'FAIL'
              print(f'{status}: {metric} = {value:.3f} (threshold: {threshold})')
              if value < threshold:
                  failed = True
          if failed:
              print('\nQuality gate FAILED!')
              sys.exit(1)
          print('\nAll quality gates PASSED!')
          "

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ragas-test-results
          path: |
            hometask_9/ragas_results.json
            hometask_9/evaluation_metrics.csv
            hometask_9/test-results.xml
            hometask_9/*.png

      - name: Upload executed notebook
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: executed-notebook
          path: hometask_9/hometask_9_executed.ipynb

  report:
    name: Generate Report
    runs-on: ubuntu-latest
    needs: ragas-tests
    if: always()

    steps:
      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          name: ragas-test-results
          path: results/

      - name: Generate summary
        run: |
          python -c "
          import json
          with open('results/ragas_results.json') as f:
              results = json.load(f)
          metrics = results['aggregate_metrics']
          print('## Ragas Evaluation Results')
          print('| Metric | Score | Threshold | Status |')
          print('|--------|-------|-----------|--------|')
          for metric, value in metrics.items():
              threshold = results['thresholds'].get(metric, 'N/A')
              status = 'Pass' if value >= threshold else 'Fail'
              print(f'| {metric} | {value:.3f} | {threshold} | {status} |')
          " >> $GITHUB_STEP_SUMMARY
